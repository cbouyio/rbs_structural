{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet RBS structural "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "...\n",
    "RBPs : qlqs lignes + figure + role dans régulation + role spécifique dans Traduction \n",
    "\n",
    "Les reads pour les protéines de liaison à l'ARN (RBP) reflètent le nombre d'interactions entre une RBP spécifique et un ARN particulier associé à chaque gène dans un tableau. Ces données sont généralement obtenues par des techniques comme eCLIP (Enhanced CrossLinking and ImmunoPrecipitation), qui permettent de détecter les sites de liaison en utilisant un cross-linking chimique pour stabiliser l'interaction entre les RBPs et l'ARN, suivi d'une immunoprécipitation pour isoler les complexes RBP-ARN. (generalement dans introduction). \n",
    "\n",
    "provenance données : Sypher \n",
    "- expliquer exactement comment Sypher a recuperé ces données\n",
    "\n",
    "Pblm : Trouver les motifs structurales des RBPs qui sont impliqués dans les liaisons à l'ARNm concernant spécifiquement la traduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "## Input Data \n",
    "\n",
    "- Pre-processing of the data : \n",
    "how he obtained the data \n",
    "find a exp ribosome profiling, trouver des cells lines that are same \n",
    "data from E-Clip exp -> extended from a data ribosome profile \n",
    "RBP df \n",
    "\n",
    "Fichier : data_raw.csv \n",
    "Le fichier contient  17,670 lignes, ou chaque ligne représente un gène spécifique, et il y a 144 colonnes. \n",
    "La première colonne, Geneid, contient les identifiants des gènes.\n",
    "Les colonnes suivantes représentent des valeurs numériques associées aux RBPs pour chaque gène, données proveant de e-CLIP.\n",
    "Les quatre dernières colonnes contiennent les données de ribosome profiling d'une meme lignée cellulaire depuis RPF db. \n",
    "\n",
    "Une fois isolés, les complexes sont séquencés pour identifier les fragments d'ARN liés à chaque RBP, ce qui permet de quantifier le nombre de reads pour chaque gène. Ces chiffres sont essentiels car ils fournissent des informations sur le rôle des RBPs dans la régulation post-transcriptionnelle.\n",
    "\n",
    "4 dernières colonnes = conditions expérimentales spécifiques :\n",
    "\n",
    "- shScramble : Données de contrôle obtenues avec un siRNA \"scramble\" qui ne cible aucun gène, servant de référence pour évaluer les autres traitements.\n",
    "- shDDX41 : Données où l'expression du gène DDX41 est inhibée par un shRNA spécifique. Cela permet d'étudier l'impact de cette inhibition sur la traduction des gènes, DDX41 étant impliqué dans la régulation de la traduction et de la maturation des ARN.\n",
    "- DMSO : Données pour les cellules traitées avec DMSO, un solvant utilisé comme contrôle pour s'assurer que les effets observés ne proviennent pas simplement de la présence du solvant.\n",
    "- CX5461 : Données pour les cellules traitées avec CX5461, un composé inhibant la synthèse des ARN ribosomiques. Cela permet d'analyser l'effet de ce traitement sur la traduction des gènes en comparaison avec les conditions de contrôle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Geneid  DDX1  XRCC6  GEMIN5  DROSHA  HNRNPUL1  FTO  MORC2  SSB  \\\n",
      "0   ENSG00000186092.7   0.0    0.0     0.0     0.0       0.0  0.0    0.0  0.0   \n",
      "1   ENSG00000284733.2   0.0    0.0     0.0     0.0       0.0  0.0    0.0  0.0   \n",
      "2   ENSG00000284662.2   0.0    0.0     0.0     0.0       0.0  0.0    0.0  0.0   \n",
      "3  ENSG00000187634.13   0.0    0.0     0.0     0.0       0.0  0.0    0.0  0.0   \n",
      "4  ENSG00000188976.11   0.0    0.0     0.0     0.0       0.0  0.0    0.0  0.0   \n",
      "\n",
      "   U2AF2  ...  PPIL4  EEF2  SUPV3L1  DDX6      UPF1  TIA1  shScramble  \\\n",
      "0    0.0  ...    0.0   0.0      0.0   0.0  0.000000   0.0    0.000000   \n",
      "1    0.0  ...    0.0   0.0      0.0   0.0  0.000000   0.0    0.000000   \n",
      "2    0.0  ...    0.0   0.0      0.0   0.0  0.000000   0.0    0.000000   \n",
      "3    0.0  ...    0.0   0.0      0.0   0.0  0.000000   0.0    1.146767   \n",
      "4    0.0  ...    0.0   0.0      0.0   0.0  3.674923   0.0  122.630332   \n",
      "\n",
      "      shDDX41        DMSO      CX5461  \n",
      "0    0.000000    0.000000    0.000000  \n",
      "1    0.000000    0.000000    0.000000  \n",
      "2    0.000000    0.000000    0.000000  \n",
      "3    1.151633    0.000000    0.662869  \n",
      "4  137.026864  179.017168  164.731406  \n",
      "\n",
      "[5 rows x 144 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17670 entries, 0 to 17669\n",
      "Columns: 144 entries, Geneid to CX5461\n",
      "dtypes: float64(143), object(1)\n",
      "memory usage: 19.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/data_raw.csv')\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation données \n",
    "Vu que les 4 dernieres colonnes correspondent à des conditions experimentales (pas des RBPs directement), on va séparer le data_raw en 2 jeu de données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/data_raw.csv\")\n",
    "\n",
    "df_eclip = df.iloc[:, :-4]\n",
    "df_rpf = df.iloc[:, [0] + list(range(len(df.columns)-4, len(df.columns)))]  # Garde la première colonne + les 4 dernières\n",
    "\n",
    "df_eclip.to_csv(\"df_eclip.csv\", index=False, header=True)\n",
    "df_rpf.to_csv(\"df_rpf.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche des motifs structuraux des RBPs du data \n",
    "\n",
    "## 1- Récupération des Identifiants UniProt\n",
    "Ecriture d'un script Python qui utilise l'API UniProt pour rechercher les identifiants des protéines RBP en fonction de leurs noms, contenu dans le fichier df_eclip.csv. La fonction get_uniprot_ids a été conçue pour traiter chaque nom de RBP et récupérer son identifiant UniProt correspondant, en veillant à ce que seuls les identifiants associés aux protéines humaines soient retenus. \n",
    "A l'issue de cette étape, on recupere les identifants de nos 139 RBPs. \n",
    "\n",
    "## 2- Création des URLs d'UniProt\n",
    "Pour faciliter l'accès aux pages détaillées des RBPs sur le site d'UniProt, nous avons généré des URLs à partir des identifiants obtenus. Ces URLs ont été enregistrées dans un fichier CSV (uniprot_urls.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom de la protéine   Identifiant UniProt\n",
      "----------------------------------------\n",
      "DDX1                 Q92499\n",
      "XRCC6                P12956\n",
      "GEMIN5               Q8TEQ6\n",
      "DROSHA               Q9NRR4\n",
      "HNRNPUL1             Q9BUJ2\n",
      "FTO                  Q9C0B1\n",
      "MORC2                Q9Y6X9\n",
      "SSB                  Q04837\n",
      "U2AF2                P26368\n",
      "CSTF2T               Q9H0L4\n",
      "LARP7                Q4G0J3\n",
      "SLBP                 Q14493\n",
      "EFTUD2               Q15029\n",
      "TAF15                Q92804\n",
      "ELAC2                Q9BQ52\n",
      "RYBP                 Q8N488\n",
      "WDR43                Q15061\n",
      "HNRNPC               P07910\n",
      "AGGF1                Q8N302\n",
      "SF3B1                O75533\n",
      "APOBEC3C             Q9NRW3\n",
      "GARS                 P41250\n",
      "RNF187               Q5TA31\n",
      "SRSF1                Q07955\n",
      "KHDRBS1              Q07666\n",
      "YBX3                 P16989\n",
      "RPS10                P46783\n",
      "SDAD1                Q9NVU7\n",
      "HNRNPA1              P09651\n",
      "ZNF800               Q2TB10\n",
      "BUD13                Q9BRD0\n",
      "PRPF8                Q6P2Q9\n",
      "KHSRP                Q92945\n",
      "PUM1                 Q14671\n",
      "DDX43                Q9NXZ2\n",
      "FUS                  P35637\n",
      "AKAP8L               Q9ULX6\n",
      "GPKOW                Q92917\n",
      "RPS6                 P62753\n",
      "SRSF7                Q16629\n",
      "DDX42                Q86XP3\n",
      "ZC3H8                Q8N5P1\n",
      "APEX1                P27695\n",
      "SMNDC1               O75940\n",
      "ILF3                 Q12906\n",
      "FASTKD2              Q9NYY8\n",
      "ZC3H11A              O75152\n",
      "SRSF9                Q13242\n",
      "EXOSC5               Q9NQT4\n",
      "AATF                 Q9NY61\n",
      "SERBP1               Q8NC51\n",
      "FAM120A              Q9NZB2\n",
      "NPM1                 P06748\n",
      "SLTM                 Q9NWH9\n",
      "SBDS                 Q9Y3A5\n",
      "RBFOX2               O43251\n",
      "DDX55                Q8NHQ9\n",
      "SAFB2                Q14151\n",
      "MBNL1                Q9NR56\n",
      "SF3B4                Q15427\n",
      "HLTF                 Q14527\n",
      "ELAVL1               Q15717\n",
      "ZNF622               Q969S3\n",
      "AARS                 P49588\n",
      "SND1                 Q7KZF4\n",
      "MATR3                P43243\n",
      "ADAT1                Q9BUB4\n",
      "MTPAP                Q9NVV4\n",
      "NOLC1                Q14978\n",
      "UCHL5                Q9Y5K5\n",
      "DGCR8                Q8WYQ5\n",
      "ZRANB2               O95218\n",
      "FMR1                 Q06787\n",
      "PHF6                 Q8IWS0\n",
      "TBRG4                Q969Z0\n",
      "PUS1                 Q9Y606\n",
      "DDX21                Q9NR30\n",
      "NCBP2                P52298\n",
      "IGF2BP2              Q9Y6M1\n",
      "AQR                  O60306\n",
      "FXR1                 P51114\n",
      "NIPBL                Q6KC79\n",
      "METTL1               Q9UBP6\n",
      "ABCF1                Q8NE71\n",
      "SAFB                 Q15424\n",
      "WDR3                 Q9UNX4\n",
      "LIN28B               Q6ZN17\n",
      "DDX51                Q8N8A6\n",
      "EIF4G2               P78344\n",
      "IGF2BP1              Q9NZI8\n",
      "PUM2                 Q8TB72\n",
      "NSUN2                Q08J23\n",
      "HNRNPM               P52272\n",
      "RPS11                P62280\n",
      "DDX24                Q9GZR7\n",
      "FXR2                 P51116\n",
      "METAP2               P50579\n",
      "AKAP1                Q92667\n",
      "U2AF1                Q01081\n",
      "DDX3X                O00571\n",
      "UTP18                Q9Y5J1\n",
      "LSM11                P83369\n",
      "TRA2A                Q13595\n",
      "EIF4E                P06730\n",
      "CPEB4                Q17RY0\n",
      "GTF2F1               P35269\n",
      "PTBP1                P26599\n",
      "UTP3                 Q9NQZ2\n",
      "GNL3                 Q9BVP2\n",
      "HNRNPK               P61978\n",
      "LARP4                Q71RC2\n",
      "RPS3                 P23396\n",
      "TARDBP               Q13148\n",
      "GRWD1                Q9BQ67\n",
      "XRN2                 Q9H0D6\n",
      "HNRNPL               P14866\n",
      "EWSR1                Q01844\n",
      "DHX30                Q7L2E3\n",
      "CPSF6                Q16630\n",
      "PCBP1                Q15365\n",
      "DDX47                Q9H0S4\n",
      "HNRNPU               Q00839\n",
      "RBM15                Q96T37\n",
      "EXOSC10              Q01780\n",
      "TROVE2               P10155\n",
      "QKI                  Q96PU8\n",
      "WRN                  Q14191\n",
      "DDX52                Q9Y2R4\n",
      "RBM22                Q9NW64\n",
      "EIF3G                O75821\n",
      "PABPC4               Q13310\n",
      "YWHAG                P61981\n",
      "NONO                 Q15233\n",
      "PPIL4                Q8WUA2\n",
      "EEF2                 P13639\n",
      "SUPV3L1              Q8IYB8\n",
      "DDX6                 P26196\n",
      "UPF1                 Q92900\n",
      "TIA1                 P31483\n"
     ]
    }
   ],
   "source": [
    "# execution en 1m36s\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_uniprot_ids(rbp_names):\n",
    "    \"\"\"\n",
    "    Récupère les identifiants UniProt pour une liste de noms de protéines (RBPs).\n",
    "\n",
    "    Args:\n",
    "        rbp_names (list): Une liste de noms de protéines (RBPs) à rechercher.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant les identifiants UniProt pour chaque RBP,\n",
    "              ou un message d'erreur si aucun identifiant n'est trouvé.\n",
    "    \"\"\"\n",
    "    # URL de l'API UniProt pour la recherche\n",
    "    url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    \n",
    "    # Dictionnaire (noms RBPs comme key et uniprot_id comme value)\n",
    "    uniprot_ids = {} \n",
    "\n",
    "    for rbp in rbp_names:\n",
    "        params = {\n",
    "            \"query\": rbp,  # Recherche par nom de RBP\n",
    "            \"format\": \"json\",   # Format JSON\n",
    "            \"size\": 10          # Limite le nombre de résultats à 10\n",
    "        }\n",
    "        \n",
    "        # Envoi de la requête GET à l'API\n",
    "        response = requests.get(url, params=params)\n",
    "        \n",
    "        # Vérification du statut de la requête\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Filtre les résultats pour trouver la protéine humaine\n",
    "            for result in data.get('results', []):\n",
    "                if 'HUMAN' in result.get('uniProtkbId', ''):\n",
    "                    uniprot_ids[rbp] = result['primaryAccession']\n",
    "                    break  \n",
    "            else:\n",
    "                uniprot_ids[rbp] = \"Aucun identifiant trouvé pour cette protéine.\"\n",
    "        else:\n",
    "            uniprot_ids[rbp] = f\"Erreur: {response.status_code}\"\n",
    "    \n",
    "    return uniprot_ids\n",
    "\n",
    "\n",
    "df = pd.read_csv('df_eclip.csv')  \n",
    "# Extraire les noms des RBPs à partir de la première ligne en excluant la colonne 'geneid'\n",
    "rbp_names = df.columns.tolist()[1:] \n",
    "\n",
    "uniprot_results = get_uniprot_ids(rbp_names)\n",
    "print(f\"{'Nom de la protéine':<20} {'Identifiant UniProt'}\")\n",
    "print('-' * 40)\n",
    "for rbp, uniprot_id in uniprot_results.items():\n",
    "    print(f\"{rbp:<20} {uniprot_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Les URLs ont été enregistrées dans 'uniprot_urls.csv'.\n",
      "Nombre total d'URLs dans le fichier: 139\n",
      "\n",
      "Les 5 premières lignes du fichier sont :\n",
      "  Nom de la protéine                             URL UniProt\n",
      "0               DDX1  https://www.uniprot.org/uniprot/Q92499\n",
      "1              XRCC6  https://www.uniprot.org/uniprot/P12956\n",
      "2             GEMIN5  https://www.uniprot.org/uniprot/Q8TEQ6\n",
      "3             DROSHA  https://www.uniprot.org/uniprot/Q9NRR4\n",
      "4           HNRNPUL1  https://www.uniprot.org/uniprot/Q9BUJ2\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "base_url = \"https://www.uniprot.org/uniprot/\"\n",
    "uniprot_urls = {}\n",
    "\n",
    "# Enregistrement des URLs dans un fichier CSV\n",
    "with open(\"uniprot_urls.csv\", \"w\", newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Nom de la protéine', 'URL UniProt'])  # Header\n",
    "    for rbp, uniprot_id in uniprot_results.items():\n",
    "        if \"Aucun\" not in uniprot_id and \"Erreur\" not in uniprot_id:\n",
    "            url = f\"{base_url}{uniprot_id}\"\n",
    "            uniprot_urls[rbp] = url\n",
    "            csv_writer.writerow([rbp, url])\n",
    "        else:\n",
    "            csv_writer.writerow([rbp, uniprot_id])\n",
    "\n",
    "print(\"\\nLes URLs ont été enregistrées dans 'uniprot_urls.csv'.\")\n",
    "\n",
    "# Checking que le fichier est bon \n",
    "import pandas as pd\n",
    "df_urls = pd.read_csv('uniprot_urls.csv')\n",
    "print(f\"Nombre total d'URLs dans le fichier: {len(df_urls)}\")\n",
    "print(\"\\nLes 5 premières lignes du fichier sont :\")\n",
    "print(df_urls.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Recupération des informations structurales \n",
    "\n",
    "L'API UniProt permet de récupérer des informations détaillées sur les protéines, notamment les features qui décrivent les régions fonctionnelles et structurelles. Pour chaque identifiant UniProt, nous avons effectué des requêtes API pour extraire des données au format JSON. Les features comprennent des informations telles que le type, la description, la localisation, l'identifiant et les preuves associées. \n",
    "Ces données ont été organisées et stockées dans un fichier CSV (uniprot_structural_info.csv), facilitant ainsi l'analyse et la visualisation des caractéristiques structurales des protéines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code qui permet de récuperer le fichier all_infos : \n",
    "- rbp : nom de la protéine liant l'ARN.\n",
    "- uniprot_id : identifiant UniProt de chaque RBP.\n",
    "- features : toutes les caractéristiques structurales de chaque RBP.\n",
    "- motif_info : caractéristiques de type \"motif\" et \"binding site\" uniquement.\n",
    "- No_feat : nombre total de caractéristiques.\n",
    "- Binding_site : IDs uniques des évidences pour les sites de liaison, séparés par des points-virgules.\n",
    "- Motifs : IDs uniques des évidences pour les motifs, séparés par des points-virgules.\n",
    "- Domains : IDs uniques des évidences pour les domaines, séparés par des points-virgules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations structurelles sauvegardées dans le fichier 'all_infos.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_structural_info(uniprot_results):\n",
    "    \"\"\"\n",
    "    Récupère les informations structurelles pour une liste d'identifiants UniProt, incluant les motifs, domaines et sites de liaison.\n",
    "\n",
    "    Args:\n",
    "        uniprot_results (dict): Un dictionnaire contenant des noms de RBPs et leurs identifiants UniProt.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste de dictionnaires contenant les informations structurelles pour chaque identifiant.\n",
    "    \"\"\"\n",
    "    structural_info = []\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/{id}.json\"\n",
    "\n",
    "    for rbp, uniprot_id in uniprot_results.items():\n",
    "        url = base_url.format(id=uniprot_id)\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "\n",
    "            # Initialisation des listes pour les caractéristiques spécifiques\n",
    "            motif_info = []  # Contient uniquement les caractéristiques de type \"motif\" ou \"binding\"\n",
    "            binding_site_ids = []\n",
    "            motif_ids = []\n",
    "            domain_ids = []\n",
    "\n",
    "            feature_details = []  # Contient toutes les caractéristiques, pour la colonne `features`\n",
    "            \n",
    "            for feature in features:\n",
    "                feature_type = feature.get('type', 'N/A').lower()\n",
    "                feature_data = {\n",
    "                    'type': feature.get('type', 'N/A'),\n",
    "                    'description': feature.get('description', 'N/A'),\n",
    "                    'location': feature.get('location', 'N/A'),\n",
    "                    'evidences': feature.get('evidences', [])\n",
    "                }\n",
    "                feature_details.append(feature_data)\n",
    "\n",
    "                # Ajouter dans motif_info si le type est \"motif\" ou \"binding site\"\n",
    "                if \"binding site\" in feature_type or \"motif\" in feature_type:\n",
    "                    motif_info.append(feature_data)\n",
    "\n",
    "                # Extraction des IDs d'évidence pour chaque type : Binding site, Motif, Domain\n",
    "                if \"binding site\" in feature_type:\n",
    "                    for evidence in feature.get('evidences', []):\n",
    "                        evidence_id = evidence.get('id') or evidence.get('evidenceCode')\n",
    "                        if evidence_id is not None and evidence_id not in binding_site_ids:\n",
    "                            binding_site_ids.append(evidence_id)\n",
    "                \n",
    "                elif \"motif\" in feature_type:\n",
    "                    for evidence in feature.get('evidences', []):\n",
    "                        evidence_id = evidence.get('id') or evidence.get('evidenceCode')\n",
    "                        if evidence_id is not None and evidence_id not in motif_ids:\n",
    "                            motif_ids.append(evidence_id)\n",
    "                \n",
    "                elif \"domain\" in feature_type:\n",
    "                    for evidence in feature.get('evidences', []):\n",
    "                        evidence_id = evidence.get('id') or evidence.get('evidenceCode')\n",
    "                        if evidence_id is not None and evidence_id not in domain_ids:\n",
    "                            domain_ids.append(evidence_id)\n",
    "\n",
    "            # Compilation des informations pour chaque RBP\n",
    "            structural_info.append({\n",
    "                'rbp': rbp,\n",
    "                'uniprot_id': uniprot_id,\n",
    "                'features': feature_details,  # Contient toutes les caractéristiques pour chaque RBP\n",
    "                'motif_info': motif_info,  # Regroupe uniquement les motifs et sites de liaison\n",
    "                'No_feat': len(features),  \n",
    "                'Binding_site': \";\".join(binding_site_ids),  # IDs de Binding site séparés par ;\n",
    "                'Motifs': \";\".join(motif_ids),  # IDs de Motif séparés par ;\n",
    "                'Domains': \";\".join(domain_ids)  # IDs de Domain séparés par ;\n",
    "            })\n",
    "        else:\n",
    "            structural_info.append({\n",
    "                'rbp': rbp,\n",
    "                'uniprot_id': uniprot_id,\n",
    "                'error': f\"Erreur: {response.status_code}\",\n",
    "                'No_feat': 0,  # 0 si échec de récupération\n",
    "                'Binding_site': \"\",\n",
    "                'Motifs': \"\",\n",
    "                'Domains': \"\",\n",
    "                'features': [],  # Vide en cas d'erreur\n",
    "                'motif_info': []  # Vide en cas d'erreur\n",
    "            })\n",
    "\n",
    "    return structural_info\n",
    "\n",
    "structural_results = fetch_structural_info(uniprot_results)\n",
    "df_structural = pd.DataFrame(structural_results)\n",
    "\n",
    "# Save the DataFrame with the new columns for features, motif_info, Binding_site, Motifs, and Domains\n",
    "df_structural.to_csv('all_infos.csv', index=False)\n",
    "print(\"Informations structurelles sauvegardées dans le fichier 'all_infos.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tri des infirmations récupérées \n",
    "Fichier après tri, on garde uniquement les données qui nous intéressent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations structurelles sauvegardées dans le fichier 'RBP_infos.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_structural_info(uniprot_results):\n",
    "    \"\"\"\n",
    "    Récupère les informations structurelles pour une liste d'identifiants UniProt, incluant les motifs, domaines et sites de liaison.\n",
    "\n",
    "    Args:\n",
    "        uniprot_results (dict): Un dictionnaire contenant des noms de RBPs et leurs identifiants UniProt.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste de dictionnaires contenant les informations structurelles pour chaque identifiant.\n",
    "    \"\"\"\n",
    "    structural_info = []\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/{id}.json\"\n",
    "\n",
    "    for rbp, uniprot_id in uniprot_results.items():\n",
    "        url = base_url.format(id=uniprot_id)\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "\n",
    "            # Initialisation des listes pour stocker les IDs de chaque type spécifique\n",
    "            binding_site_ids = []\n",
    "            motif_ids = []\n",
    "            domain_ids = []\n",
    "            \n",
    "            # Compte le nombre total de caractéristiques\n",
    "            no_features = len(features)\n",
    "            \n",
    "            for feature in features:\n",
    "                feature_type = feature.get('type', 'N/A').lower()\n",
    "\n",
    "                # Extraction des IDs ou evidenceCode pour chaque type : Binding site, Motif, Domain\n",
    "                if \"binding site\" in feature_type:\n",
    "                    for evidence in feature.get('evidences', []):\n",
    "                        evidence_id = evidence.get('id') or evidence.get('evidenceCode')\n",
    "                        if evidence_id is not None and evidence_id not in binding_site_ids:\n",
    "                            binding_site_ids.append(evidence_id)\n",
    "                \n",
    "                elif \"motif\" in feature_type:\n",
    "                    for evidence in feature.get('evidences', []):\n",
    "                        evidence_id = evidence.get('id') or evidence.get('evidenceCode')\n",
    "                        if evidence_id is not None and evidence_id not in motif_ids:\n",
    "                            motif_ids.append(evidence_id)\n",
    "                \n",
    "                elif \"domain\" in feature_type:\n",
    "                    for evidence in feature.get('evidences', []):\n",
    "                        evidence_id = evidence.get('id') or evidence.get('evidenceCode')\n",
    "                        if evidence_id is not None and evidence_id not in domain_ids:\n",
    "                            domain_ids.append(evidence_id)\n",
    "\n",
    "            # Compilation des informations pour chaque RBP avec les colonnes demandées\n",
    "            structural_info.append({\n",
    "                'rbp_name': rbp,\n",
    "                'uniprotID': uniprot_id,\n",
    "                'No_Features': no_features,  # Total des caractéristiques\n",
    "                'motifs': \";\".join(motif_ids),  # IDs de Motif séparés par ;\n",
    "                'binding_Sites': \";\".join(binding_site_ids),  # IDs de Binding site séparés par ;\n",
    "                'domains': \";\".join(domain_ids)  # IDs de Domain séparés par ;\n",
    "            })\n",
    "        else:\n",
    "            structural_info.append({\n",
    "                'rbp_name': rbp,\n",
    "                'uniprotID': uniprot_id,\n",
    "                'No_Features': 0,  # 0 si échec de récupération\n",
    "                'motifs': \"\",\n",
    "                'binding_Sites': \"\",\n",
    "                'domains': \"\"\n",
    "            })\n",
    "\n",
    "    return structural_info\n",
    "\n",
    "structural_results = fetch_structural_info(uniprot_results)\n",
    "df_structural = pd.DataFrame(structural_results)\n",
    "\n",
    "# Save the DataFrame with only the specified columns\n",
    "df_structural.to_csv('RBP_infos.csv', index=False)\n",
    "print(\"Informations structurelles sauvegardées dans le fichier 'RBP_infos.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
